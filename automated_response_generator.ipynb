{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omKQznQRPGBu",
        "outputId": "6359c52d-a345-4bdc-efba-653fe734ad42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "                                   query  \\\n",
            "0           My order hasn't arrived yet.   \n",
            "1          I received a damaged product.   \n",
            "2              I need to return an item.   \n",
            "3  I want to change my shipping address.   \n",
            "4       I have a question about my bill.   \n",
            "\n",
            "                                            response  \n",
            "0  We apologize for the inconvenience. Can you pl...  \n",
            "1  We apologize for the inconvenience. Can you pl...  \n",
            "2  Certainly. Please provide your order number an...  \n",
            "3  No problem. Can you please provide your order ...  \n",
            "4  We'd be happy to help. Can you please provide ...  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74 entries, 0 to 73\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   query     74 non-null     object\n",
            " 1   response  74 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.3+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data_path = \"//content/Customer-Support.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Explore the dataset\n",
        "print(df.head())\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8-ynoWetZyBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access the dataset (if needed)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install transformers pandas\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Load the dataset\n",
        "data_path = \"//content/Customer-Support.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(\"Dataset Head:\\n\", df.head())\n",
        "print(\"\\nDataset Info:\\n\", df.info())\n",
        "\n",
        "# Check for missing values and handle them\n",
        "df.dropna(subset=['query', 'response'], inplace=True)\n",
        "\n",
        "# Define a custom dataset class\n",
        "class SupportDataset(Dataset):\n",
        "    def __init__(self, queries, responses, tokenizer, max_length=512):\n",
        "        self.queries = queries\n",
        "        self.responses = responses\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.queries)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        query = str(self.queries[idx])\n",
        "        response = str(self.responses[idx])\n",
        "\n",
        "        input_text = \"query: \" + query + \" </s>\"\n",
        "        target_text = response + \" </s>\"\n",
        "\n",
        "        input_ids = self.tokenizer.encode(input_text, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        target_ids = self.tokenizer.encode(target_text, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "\n",
        "        return {\"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
        "                \"attention_mask\": torch.tensor([int(i != 0) for i in input_ids], dtype=torch.long),\n",
        "                \"decoder_input_ids\": torch.tensor(target_ids, dtype=torch.long),\n",
        "                \"decoder_attention_mask\": torch.tensor([int(i != 0) for i in target_ids], dtype=torch.long),\n",
        "                \"labels\": torch.tensor(target_ids, dtype=torch.long)}\n",
        "\n",
        "# Tokenizer and model initialization\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "\n",
        "# Create train and validation datasets\n",
        "# Adjust the split ratio if needed\n",
        "train_size = int(0.8 * len(df))\n",
        "val_size = len(df) - train_size\n",
        "\n",
        "# Use iloc to ensure correct slicing of the DataFrame\n",
        "train_dataset = SupportDataset(df.iloc[:train_size]['query'].tolist(), df.iloc[:train_size]['response'].tolist(), tokenizer)\n",
        "val_dataset = SupportDataset(df.iloc[train_size:]['query'].tolist(), df.iloc[train_size:]['response'].tolist(), tokenizer)\n",
        "\n",
        "# Check if the validation dataset is empty\n",
        "if len(val_dataset) == 0:\n",
        "    print(\"Warning: Validation dataset is empty. Check your data splitting logic.\")\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch in loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Validation function\n",
        "def validate_epoch(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "for epoch in range(3):\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "    val_loss = validate_epoch(model, val_loader, device)\n",
        "    print(f\"Epoch {epoch+1}: Train Loss - {train_loss}, Val Loss - {val_loss}\")\n",
        "\n",
        "# Function to generate response\n",
        "def generate_response(query, model, tokenizer, device):\n",
        "    input_text = \"query: \" + query + \" </s>\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(input_ids=input_ids, max_length=100, num_beams=4, early_stopping=True)\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Example usage of the generate_response function and updating the dataframe with generated responses\n",
        "df['generated_response'] = df['query'].apply(lambda query: generate_response(query, model, tokenizer, device))\n",
        "\n",
        "# Save the updated dataframe to a new CSV file\n",
        "output_path = \"//content/Customer-Support-with-Generated-Responses.csv\"\n",
        "df.to_csv(output_path, index=False)\n",
        "print(f\"Updated dataset saved to {output_path}\")\n",
        "\n",
        "# Display the first few rows of the updated dataframe\n",
        "print(\"Updated Dataset Head:\\n\", df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJHkRQD7dqQK",
        "outputId": "711d6c1f-1888-4012-e8be-5b5451785c9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Dataset Head:\n",
            "                                    query  \\\n",
            "0           My order hasn't arrived yet.   \n",
            "1          I received a damaged product.   \n",
            "2              I need to return an item.   \n",
            "3  I want to change my shipping address.   \n",
            "4       I have a question about my bill.   \n",
            "\n",
            "                                            response  \n",
            "0  We apologize for the inconvenience. Can you pl...  \n",
            "1  We apologize for the inconvenience. Can you pl...  \n",
            "2  Certainly. Please provide your order number an...  \n",
            "3  No problem. Can you please provide your order ...  \n",
            "4  We'd be happy to help. Can you please provide ...  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 74 entries, 0 to 73\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   query     74 non-null     object\n",
            " 1   response  74 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.3+ KB\n",
            "\n",
            "Dataset Info:\n",
            " None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:290: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss - 6.658987029393514, Val Loss - 0.24868833646178246\n",
            "Epoch 2: Train Loss - 0.9467533747355144, Val Loss - 0.2332465499639511\n",
            "Epoch 3: Train Loss - 0.6729626258214315, Val Loss - 0.22342728078365326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:290: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated dataset saved to //content/Customer-Support-with-Generated-Responses.csv\n",
            "Updated Dataset Head:\n",
            "                                    query  \\\n",
            "0           My order hasn't arrived yet.   \n",
            "1          I received a damaged product.   \n",
            "2              I need to return an item.   \n",
            "3  I want to change my shipping address.   \n",
            "4       I have a question about my bill.   \n",
            "\n",
            "                                            response generated_response  \n",
            "0  We apologize for the inconvenience. Can you pl...                     \n",
            "1  We apologize for the inconvenience. Can you pl...                     \n",
            "2  Certainly. Please provide your order number an...                     \n",
            "3  No problem. Can you please provide your order ...                     \n",
            "4  We'd be happy to help. Can you please provide ...                     \n"
          ]
        }
      ]
    }
  ]
}